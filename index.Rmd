---
title: "Machine Learning Project"
author: "Jane Carlson"
date: "7/19/2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### Practical Machine Learning Project
Predicting the results of barbell lifts from accelerometer data on the belt, forearm, arm and dumbbell of six male participants who range from 20-28 years of age.  The data is provided from http://groupware.les.inf.puc-rio.br/har and is already split into training and testing sets.  The goal is to predict the twenty observations in the testing set for the "classe" variable.

## Cleaning the Data
There are 160 variable in both data sets.  Of the variables, 53 contain enough data to be considered for the model.  Using external sources to get the column number and names, the columns of the original data to keep were determined to be columns 8-11, 37-49, 60-68, 84-86, 102, 113-124, 140, 151-160.

For cross-validation, I further divide the training set into training and testing data.  Try different models on the training subset and fit the model on the testing subset of the training file.  Look for the model that yields at least 99% accuracy. 

###Loading libraries.
```{r, echo=FALSE}
library(caret)
library(randomForest)
trainURL <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
validateURL <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
destfiletrain <- "training.csv"
destfilevalidate <- "validate.csv"
download.file(trainURL, destfiletrain, method="curl")
download.file(validateURL, destfilevalidate, method="curl")
trainfile = read.csv("~/Projects/8 Machine Learning/training.csv")
validatefile = read.csv("~/Projects/8 Machine Learning/validate.csv")
traindat <- trainfile[,c(8:11,37:49,60:68, 84:86, 102, 113:124,140, 151:160)]
validatedat <- validatefile[,c(8:11,37:49,60:68, 84:86, 102, 113:124,140, 151:160)]
```
## Create a test set from the training data and run a model, test accuracy and try another
```{r}
inTrain <- createDataPartition(y=traindat$classe, p=3/4, list=FALSE)
training <- traindat[inTrain,]
testing <- traindat[-inTrain,]
```

### Model with method = rpart
The rpart method gives 0.49 accuracy which is not sufficient so will need to try another model.  The out of sample error is 0.51.

```{r, echo=FALSE}
set.seed(12345)
inTrain <- createDataPartition(y=traindat$classe, p=3/4, list=FALSE)
training <- traindat[inTrain,]
testing <- traindat[-inTrain,]
set.seed(12345)
modFit <- train(classe~., data=training, method="rpart")
predictrp <- predict(modFit,newdata=testing)
confusionMatrix(predictrp, testing$classe)
```

### Model with method = lda
The lda method gives 0.70 accuracy which is not sufficient so will need to try another model.  The out of sample error is 0.30.
```{r, echo=FALSE}
modFitlda <-train(classe~., data=training, method="lda")
predictlda <- predict(modFitlda, newdata=testing)
confusionMatrix(predictlda, testing$classe)
```

### Model using Random Forest
```{r, echo=FALSE}
modFitrf <- randomForest(classe ~ ., data=training, importance=FALSE)
predictrf <- predict(modFitrf, newdata=testing)
confusionMatrix(predictrf, testing$classe)
```
This yields accuracy of 0.99.  A good fit model.  Out of sample error of 0.01

### Model with complete training data to predict validating data
```{r}
modFitRanFor <- randomForest(classe ~ ., data=traindat, importance=FALSE)
predictRanFor <- predict(modFitRanFor, newdata=validatedat, type ="class")
predictRanFor
```